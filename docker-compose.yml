version: '3'
services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:${CP_STACK_VERSION}
    restart: unless-stopped
    ports:
      - 22181:22181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 22181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    networks:
      - default

  kafka-1:
    image: confluentinc/cp-kafka:${CP_STACK_VERSION}
    depends_on:
      - zookeeper-1
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:22181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:29092
      # suppress verbosity
      # https://github.com/confluentinc/cp-docker-images/blob/master/debian/kafka/include/etc/confluent/docker/log4j.properties.template
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    networks:
      - default

  kafka-create-topics:
    image: confluentinc/cp-kafka:${CP_STACK_VERSION}
    depends_on:
      - kafka-1
    # We defined a dependency on "kafka", but `depends_on` will NOT wait for the
    # dependencies to be "ready" before starting the "kafka-create-topics"
    # container;  it waits only until the dependencies have started.  Hence we
    # must control startup order more explicitly.
    # See https://docs.docker.com/compose/startup-order/
    command: |
      bash -c 'echo Waiting for Kafka to be ready... && \
      cub kafka-ready -b kafka-1:29092 1 20 && \
      kafka-topics --create --topic event --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper-1:22181 && \
      sleep infinity'
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
    networks:
      - default

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:${CP_STACK_VERSION}
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper-1:22181
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    depends_on:
      - zookeeper-1
      - kafka-1
    networks:
      - default

  kafka-create-schema:
    image: confluentinc/cp-kafka:${CP_STACK_VERSION}
    depends_on:
      - kafka-schema-registry
    command: |
      bash -c 'echo Waiting for kafka-schema-registry to be ready... && \
      cub sr-ready kafka-schema-registry 8081 20 && \
      for item in "key" "event"; do curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
        --data "{\"schema\": \"$$(python /home/app/stringify.py /home/app/avro/$$item.avsc)\" }" \
        http://kafka-schema-registry:8081/subjects/$$item/versions; done &&
      sleep infinity'
    environment:
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
    volumes:
      - ./:/home/app/
    networks:
      - default

  kafka-schema-registry-ui:
    image: landoop/schema-registry-ui:0.9.3
    ports:
      - 8001:8000
    environment:
      SCHEMAREGISTRY_URL: http://kafka-schema-registry:8081/
      PROXY: "true"
    depends_on:
      - kafka-schema-registry
    networks:
      - default

  # Note: ready when "docker logs kafka-connect | grep started"
  kafka-connect:
    image: confluentinc/cp-kafka-connect:${CP_STACK_VERSION}
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka-1:29092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      # best practices to set plugin path so no dependency version conflicts
      CONNECT_PLUGIN_PATH: /usr/local/share/kafka/plugins
    #volumes:
    #  - ./path/to/mypackage-1.0-SNAPSHOT-package/share/java/mypackage:/usr/local/share/kafka/plugins/mypackage
    networks:
      - default
    depends_on:
      - zookeeper-1
      - kafka-1
      - kafka-schema-registry

  kafka-connect-ui:
    image: landoop/kafka-connect-ui:0.9.3
    hostname: kafka-connect-ui
    ports:
      - "8002:8000"
    environment:
      CONNECT_URL: "http://kafka-connect:8083/"
      PROXY: "true"
    depends_on:
      - kafka-connect

networks:
    default:
